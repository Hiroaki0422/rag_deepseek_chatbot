{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11053625,"sourceType":"datasetVersion","datasetId":6886546},{"sourceId":11054819,"sourceType":"datasetVersion","datasetId":6887301},{"sourceId":11192945,"sourceType":"datasetVersion","datasetId":6987569},{"sourceId":11193079,"sourceType":"datasetVersion","datasetId":6987656},{"sourceId":290390,"sourceType":"modelInstanceVersion","modelInstanceId":248773,"modelId":270303},{"sourceId":291537,"sourceType":"modelInstanceVersion","modelInstanceId":249758,"modelId":271273},{"sourceId":293217,"sourceType":"modelInstanceVersion","modelInstanceId":251153,"modelId":272632},{"sourceId":305934,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":261008,"modelId":282158}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stock Predictor TFT Trainer","metadata":{}},{"cell_type":"markdown","source":"## Install dependencies","metadata":{}},{"cell_type":"code","source":"pip install pytorch-lightning pytorch-forecasting pandas numpy matplotlib optuna optuna-integration[pytorch_lightning] pytorch_optimizer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport optuna\nfrom pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\nfrom pytorch_forecasting.data import GroupNormalizer\nfrom pytorch_forecasting.metrics import QuantileLoss, MAE\nfrom lightning.pytorch import Trainer, Callback\nimport gc\nimport pickle\nfrom pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:34:00.247654Z","iopub.execute_input":"2025-04-09T05:34:00.247963Z","iopub.status.idle":"2025-04-09T05:34:10.851507Z","shell.execute_reply.started":"2025-04-09T05:34:00.247940Z","shell.execute_reply":"2025-04-09T05:34:10.850741Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load Training Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = \"/kaggle/input/2025-04-09/2025-04-09_training.csv\"\nmerged_df = pd.read_csv(data_path)\nprint(len(merged_df))\n\n# Features for input Data\nmerged_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T21:08:18.713084Z","iopub.execute_input":"2025-03-30T21:08:18.713428Z","iopub.status.idle":"2025-03-30T21:08:20.734950Z","shell.execute_reply.started":"2025-03-30T21:08:18.713403Z","shell.execute_reply":"2025-03-30T21:08:20.734099Z"}},"outputs":[{"name":"stdout","text":"252847\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0.1', 'Unnamed: 0', 'Date', 'Open', 'High', 'Low', 'Close',\n       'Volume', 'Dividends', 'Stock Splits', 'month', 'day', 'day_of_week',\n       'NASDAQ', 'SNP', 'DJI', 'RUT', 'VIX', 'XLK', 'XLE', 'XLF', 'XLV', 'RSI',\n       'MA_20', 'MA_50', 'MA_200', 'log_return', 'RV_20', 'RV_50', 'symbol',\n       'time_idx', 'sentiment'],\n      dtype='object')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"cols_to_convert = ['month', 'day', 'day_of_week']\nmerged_df[cols_to_convert] = merged_df[cols_to_convert].astype(str)\nmerged_df = merged_df[['Date', 'Open', 'High', 'Low', 'Close',\n       'Volume', 'Dividends', 'Stock Splits', 'month', 'day', 'day_of_week',\n       'NASDAQ', 'SNP', 'DJI', 'RUT', 'VIX', 'XLK', 'XLE', 'XLF', 'XLV', 'RSI',\n       'MA_20', 'MA_50', 'MA_200', 'log_return', 'RV_20', 'RV_50', 'symbol',\n       'time_idx', 'sentiment']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T21:08:21.513043Z","iopub.execute_input":"2025-03-30T21:08:21.513307Z","iopub.status.idle":"2025-03-30T21:08:21.720073Z","shell.execute_reply.started":"2025-03-30T21:08:21.513285Z","shell.execute_reply":"2025-03-30T21:08:21.719405Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"merged_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T21:08:25.863392Z","iopub.execute_input":"2025-03-30T21:08:25.863720Z","iopub.status.idle":"2025-03-30T21:08:25.894308Z","shell.execute_reply.started":"2025-03-30T21:08:25.863692Z","shell.execute_reply":"2025-03-30T21:08:25.893699Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"         Date       Open       High        Low      Close     Volume  \\\n0  2016-01-12  22.748425  22.780098  22.361553  22.614943  196616800   \n1  2016-01-13  22.696386  22.893215  22.013142  22.033503  249758400   \n2  2016-01-14  22.162462  22.732588  21.660209  22.515396  252680400   \n3  2016-01-15  21.764275  22.105898  21.574234  21.974678  319335600   \n4  2016-01-19  22.264271  22.318568  21.605912  21.868351  212350800   \n\n   Dividends  Stock Splits month day  ...        RSI      MA_20      MA_50  \\\n0        0.0           0.0     1  12  ...  32.593251  23.860620  25.516840   \n1        0.0           0.0     1  13  ...  29.187761  23.689921  25.419102   \n2        0.0           0.0     1  14  ...  31.365353  23.565829  25.323431   \n3        0.0           0.0     1  15  ...  29.198463  23.405085  25.210684   \n4        0.0           0.0     1  19  ...  30.047150  23.265721  25.098379   \n\n      MA_200  log_return     RV_20     RV_50  symbol  time_idx  sentiment  \n0  26.797160    0.014409  0.272021  0.252555    AAPL       200        0.0  \n1  26.766218   -0.026047  0.280986  0.257305    AAPL       201        0.0  \n2  26.739852    0.021635  0.295712  0.260617    AAPL       202        0.0  \n3  26.710983   -0.024309  0.298984  0.262192    AAPL       203        0.0  \n4  26.680387   -0.004850  0.293998  0.262193    AAPL       204        0.0  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Dividends</th>\n      <th>Stock Splits</th>\n      <th>month</th>\n      <th>day</th>\n      <th>...</th>\n      <th>RSI</th>\n      <th>MA_20</th>\n      <th>MA_50</th>\n      <th>MA_200</th>\n      <th>log_return</th>\n      <th>RV_20</th>\n      <th>RV_50</th>\n      <th>symbol</th>\n      <th>time_idx</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-12</td>\n      <td>22.748425</td>\n      <td>22.780098</td>\n      <td>22.361553</td>\n      <td>22.614943</td>\n      <td>196616800</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>12</td>\n      <td>...</td>\n      <td>32.593251</td>\n      <td>23.860620</td>\n      <td>25.516840</td>\n      <td>26.797160</td>\n      <td>0.014409</td>\n      <td>0.272021</td>\n      <td>0.252555</td>\n      <td>AAPL</td>\n      <td>200</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-13</td>\n      <td>22.696386</td>\n      <td>22.893215</td>\n      <td>22.013142</td>\n      <td>22.033503</td>\n      <td>249758400</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>...</td>\n      <td>29.187761</td>\n      <td>23.689921</td>\n      <td>25.419102</td>\n      <td>26.766218</td>\n      <td>-0.026047</td>\n      <td>0.280986</td>\n      <td>0.257305</td>\n      <td>AAPL</td>\n      <td>201</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-14</td>\n      <td>22.162462</td>\n      <td>22.732588</td>\n      <td>21.660209</td>\n      <td>22.515396</td>\n      <td>252680400</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>...</td>\n      <td>31.365353</td>\n      <td>23.565829</td>\n      <td>25.323431</td>\n      <td>26.739852</td>\n      <td>0.021635</td>\n      <td>0.295712</td>\n      <td>0.260617</td>\n      <td>AAPL</td>\n      <td>202</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-15</td>\n      <td>21.764275</td>\n      <td>22.105898</td>\n      <td>21.574234</td>\n      <td>21.974678</td>\n      <td>319335600</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>15</td>\n      <td>...</td>\n      <td>29.198463</td>\n      <td>23.405085</td>\n      <td>25.210684</td>\n      <td>26.710983</td>\n      <td>-0.024309</td>\n      <td>0.298984</td>\n      <td>0.262192</td>\n      <td>AAPL</td>\n      <td>203</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-19</td>\n      <td>22.264271</td>\n      <td>22.318568</td>\n      <td>21.605912</td>\n      <td>21.868351</td>\n      <td>212350800</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>19</td>\n      <td>...</td>\n      <td>30.047150</td>\n      <td>23.265721</td>\n      <td>25.098379</td>\n      <td>26.680387</td>\n      <td>-0.004850</td>\n      <td>0.293998</td>\n      <td>0.262193</td>\n      <td>AAPL</td>\n      <td>204</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 30 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Ensure non NaN in input data\nnull_counts = merged_df.isna().sum()\n\n# Display the result\nprint(null_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:52:18.930157Z","iopub.execute_input":"2025-03-28T16:52:18.930440Z","iopub.status.idle":"2025-03-28T16:52:19.007289Z","shell.execute_reply.started":"2025-03-28T16:52:18.930418Z","shell.execute_reply":"2025-03-28T16:52:19.006585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"# Clear past logs for kaggle\n!rm -r /kaggle/working/optuna_test/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:46:20.855322Z","iopub.execute_input":"2025-03-28T06:46:20.855635Z","iopub.status.idle":"2025-03-28T06:46:20.993762Z","shell.execute_reply.started":"2025-03-28T06:46:20.855591Z","shell.execute_reply":"2025-03-28T06:46:20.992633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -r /kaggle/working/lightning_logs/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:46:21.121032Z","iopub.execute_input":"2025-03-28T06:46:21.121349Z","iopub.status.idle":"2025-03-28T06:46:21.256265Z","shell.execute_reply.started":"2025-03-28T06:46:21.121319Z","shell.execute_reply":"2025-03-28T06:46:21.255385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the custom callback\nclass GarbageCollectionCallback(Callback):\n    def on_epoch_end(self, trainer: Trainer, pl_module):\n        \"\"\"\n        This method is called at the end of each epoch. \n        It forces garbage collection to free up unused memory.\n        \"\"\"\n        print(f\"Epoch {trainer.current_epoch} ended. Running garbage collection...\")\n        gc.collect()  # Manually trigger garbage collection\n        torch.cuda.empty_cache()  # Clear GPU cache\n        print(\"Garbage collection triggered.\")\n      \n    def on_train_end(self, trainer, pl_module):\n        \"\"\"\n        This method is called once, after the entire training process is finished.\n        \"\"\"\n        del trainer  # Delete the trainer object\n        gc.collect()  # Manually trigger garbage collection\n        print(\"Training has ended.\")\n\n\n# 1. Define the training dataset\nmax_prediction_length = 1   # Predict next 5 days\nmax_encoder_length = 10     # Use past 20 days for training\n\n# training_cutoff = merged_df[\"time_idx\"].max() - max_prediction_length\ncutoff_date = '2025-03-01'\ntraining_cutoff = 2320\nprint(f\"cutoff_date: {cutoff_date}\")\ntrain_data = merged_df[merged_df[\"Date\"] <= cutoff_date]\nprint(f\"trainng data: {len(train_data)}\")\nval_data = merged_df[merged_df[\"Date\"] > cutoff_date]\nprint(f\"validation data: {len(val_data)}\")\n\n# Convert to PyTorch Forecasting Dataset\ntraining = TimeSeriesDataSet(\n    train_data,\n    time_idx=\"time_idx\",\n    target=\"Close\",\n    group_ids=[\"symbol\"],  \n    max_encoder_length=max_encoder_length,\n    max_prediction_length=max_prediction_length,\n    static_categoricals=[\"symbol\"],\n    time_varying_known_categoricals=['month', 'day', 'day_of_week'],\n    time_varying_known_reals=[\"time_idx\"],\n    time_varying_unknown_reals=[\"Close\", \"Open\", \"High\", \"Low\", \"Volume\", \"RSI\", \"sentiment\", \"MA_20\", \"MA_50\", \"MA_200\", \"log_return\", \"RV_20\", \"RV_50\", 'NASDAQ', 'SNP', 'DJI', 'RUT', 'VIX', 'XLK', 'XLE', 'XLF', 'XLV', 'RSI'],\n    target_normalizer=GroupNormalizer(groups=[\"symbol\"]),\n    allow_missing_timesteps=True\n)\n\nvalidation = TimeSeriesDataSet.from_dataset(training, val_data, predict=True)\n\n# Create DataLoaders\nbatch_size = 32\ntrain_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=3)\nval_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T21:08:34.833859Z","iopub.execute_input":"2025-03-30T21:08:34.834143Z","iopub.status.idle":"2025-03-30T21:08:38.122942Z","shell.execute_reply.started":"2025-03-30T21:08:34.834122Z","shell.execute_reply":"2025-03-30T21:08:38.122285Z"}},"outputs":[{"name":"stdout","text":"cutoff_date: 2025-02-10\ntrainng data: 249743\nvalidation data: 3104\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py:1693: UserWarning: If predicting, no randomization should be possible - setting stop_randomization=True\n  warnings.warn(\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_data.groupby(\"symbol\")[\"Date\"].count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:53:15.818479Z","iopub.execute_input":"2025-03-28T16:53:15.818850Z","iopub.status.idle":"2025-03-28T16:53:15.849651Z","shell.execute_reply.started":"2025-03-28T16:53:15.818819Z","shell.execute_reply":"2025-03-28T16:53:15.848728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create hyper param tuning \n# loss_fn = QuantileLoss(quantiles=[0.4, 0.5, 0.6])\nloss_fn = MAE()\nstudy = optimize_hyperparameters(\n    train_dataloader,\n    val_dataloader,\n    model_path=\"optuna_test\",\n    n_trials=20,\n    max_epochs=10,\n    gradient_clip_val_range=(0.1, 5.0),\n    hidden_size_range=(100,128),\n    hidden_continuous_size_range=(100,128),\n    attention_head_size_range=(3, 4),\n    learning_rate_range=(0.000001, 0.1),\n    dropout_range=(0.1, 0.5),\n    trainer_kwargs=dict(limit_train_batches=500, accelerator=\"auto\"),\n    reduce_on_plateau_patience=4,\n    optimizer='adamw',\n    loss=loss_fn,\n    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:49:08.839482Z","iopub.execute_input":"2025-03-28T06:49:08.839943Z","iopub.status.idle":"2025-03-28T06:58:39.360436Z","shell.execute_reply.started":"2025-03-28T06:49:08.839908Z","shell.execute_reply":"2025-03-28T06:58:39.359408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(study.best_trial.params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:59:24.878905Z","iopub.execute_input":"2025-03-28T06:59:24.879297Z","iopub.status.idle":"2025-03-28T06:59:24.885848Z","shell.execute_reply.started":"2025-03-28T06:59:24.879260Z","shell.execute_reply":"2025-03-28T06:59:24.884870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the best hyper-parameter resulted from Optuna Tuning\nlearning_rate=study.best_trial.params['learning_rate']\nhidden_size=study.best_trial.params['hidden_size']\nattention_head_size=study.best_trial.params['attention_head_size']\ndropout=study.best_trial.params['dropout']\nhidden_continuous_size=study.best_trial.params['hidden_continuous_size']\ngradient_clip_val=study.best_trial.params['gradient_clip_val']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:59:32.393984Z","iopub.execute_input":"2025-03-28T06:59:32.394287Z","iopub.status.idle":"2025-03-28T06:59:32.399628Z","shell.execute_reply.started":"2025-03-28T06:59:32.394265Z","shell.execute_reply":"2025-03-28T06:59:32.398699Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train & Save the best Model ","metadata":{}},{"cell_type":"code","source":"from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\nfrom lightning.pytorch import Trainer\n\n# Define the checkpoint callback to save the model\ncheckpoint_callback = ModelCheckpoint(\n    dirpath=\"checkpoints\",  # Directory to save checkpoints\n    filename=\"tft_model-{epoch:02d}-{val_loss:.4f}\",  # Save the model with epoch and validation loss\n    monitor=\"val_loss\",  # Monitor the validation loss for saving the best model\n    mode=\"min\",  # Save the model with the lowest validation loss\n    save_top_k=1  # Save only the best model (change to save more if needed)\n)\n\n# Create the EarlyStopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # Metric to monitor (can also be 'val_accuracy', etc.)\n    patience=8,          # Number of epochs with no improvement before stopping\n    verbose=True,        # Print messages when stopping\n    mode='min',          # 'min' for loss (lower is better), 'max' for accuracy (higher is better)\n)\n\n\ntrainer = Trainer(\n    max_epochs=50,\n    accelerator=\"auto\",\n    enable_model_summary=True,\n    gradient_clip_val=gradient_clip_val,\n    callbacks=[checkpoint_callback, early_stopping],\n)\n\n# loss_fn = QuantileLoss(quantiles=[0.4, 0.5, 0.6])\nloss_fn = MAE()\n\ntft = TemporalFusionTransformer.from_dataset(\n    training,\n    learning_rate=learning_rate,\n    hidden_size=hidden_size,\n    attention_head_size=attention_head_size,\n    dropout=dropout,\n    hidden_continuous_size=hidden_continuous_size,\n    loss=loss_fn,\n    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n    optimizer=\"adamw\",\n    reduce_on_plateau_patience=3,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:59:39.008268Z","iopub.execute_input":"2025-03-28T06:59:39.008686Z","iopub.status.idle":"2025-03-28T06:59:39.225986Z","shell.execute_reply.started":"2025-03-28T06:59:39.008630Z","shell.execute_reply":"2025-03-28T06:59:39.225032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(\n    tft,\n    train_dataloaders=train_dataloader,\n    val_dataloaders=val_dataloader,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:01:03.694410Z","iopub.execute_input":"2025-03-28T07:01:03.694839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training Complete\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization of Predicted curve","metadata":{}},{"cell_type":"markdown","source":"## Make Prediction","metadata":{}},{"cell_type":"code","source":"# Load Trained Model\n# load the best model according to the validation loss\n# (given that we use early stopping, this is not necessarily the last epoch)\nbest_model_path = \"/kaggle/input/tft_1.1/other/default/1/tft_model-epoch09-val_loss2.5493.ckpt\"\nbest_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:37:02.858940Z","iopub.execute_input":"2025-03-30T20:37:02.859476Z","iopub.status.idle":"2025-03-30T20:37:04.251162Z","shell.execute_reply.started":"2025-03-30T20:37:02.859438Z","shell.execute_reply":"2025-03-30T20:37:04.250199Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"best_tft.to(torch.device('cpu'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightning.pytorch import Trainer\ntrainer = Trainer()\ntrainer.validate(model=best_tft, dataloaders=val_dataloader)\ntrainer.save_checkpoint(\"model_cpu.ckpt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T21:11:11.758481Z","iopub.execute_input":"2025-03-30T21:11:11.758866Z","iopub.status.idle":"2025-03-30T21:11:26.657946Z","shell.execute_reply.started":"2025-03-30T21:11:11.758839Z","shell.execute_reply":"2025-03-30T21:11:26.656691Z"}},"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae61025f3bc4a649606c27e8d20d433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ\u001b[36m \u001b[0m\u001b[36m         val_MAE         \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   2.5492842197418213    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n‚îÇ\u001b[36m \u001b[0m\u001b[36m        val_MAPE         \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.01539862435311079   \u001b[0m\u001b[35m \u001b[0m‚îÇ\n‚îÇ\u001b[36m \u001b[0m\u001b[36m        val_RMSE         \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m    3.912870168685913    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n‚îÇ\u001b[36m \u001b[0m\u001b[36m        val_SMAPE        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m  0.015477168373763561   \u001b[0m\u001b[35m \u001b[0m‚îÇ\n‚îÇ\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   2.5492842197418213    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\">      Validate metric      </span>‚îÉ<span style=\"font-weight: bold\">       DataLoader 0        </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">          val_MAE          </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    2.5492842197418213     </span>‚îÇ\n‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         val_MAPE          </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    0.01539862435311079    </span>‚îÇ\n‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         val_RMSE          </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">     3.912870168685913     </span>‚îÇ\n‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         val_SMAPE         </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">   0.015477168373763561    </span>‚îÇ\n‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    2.5492842197418213     </span>‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"def convert_gpu_to_cpu_ckpt(input_ckpt: str, output_ckpt: str):\n    print(f\"Loading model from {input_ckpt}...\")\n    model = TemporalFusionTransformer.load_from_checkpoint(\n        input_ckpt,\n        map_location=torch.device(\"cpu\")\n    )\n\n    print(\"Moving model to CPU...\")\n    model.to(torch.device(\"cpu\"))\n\n    # üõ† Patch GPU-related components (torchmetrics mostly)\n    try:\n        if hasattr(model, \"loss\"):\n            model.loss.to(torch.device(\"cpu\"))\n        if hasattr(model, \"logging_metrics\"):\n            model.logging_metrics = torch.nn.ModuleList()  # optionally keep metrics if needed\n    except Exception as e:\n        print(\"Warning while patching CUDA components:\", e)\n\n    print(f\"Saving CPU-compatible model to {output_ckpt}...\")\n    trainer = Trainer()\n    trainer.save_checkpoint(output_ckpt)\n    print(\"‚úÖ Done.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:47:51.703632Z","iopub.execute_input":"2025-03-30T20:47:51.703977Z","iopub.status.idle":"2025-03-30T20:47:51.742085Z","shell.execute_reply.started":"2025-03-30T20:47:51.703949Z","shell.execute_reply":"2025-03-30T20:47:51.741444Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Prediction for a particular symbol","metadata":{}},{"cell_type":"code","source":"def display_prediction(symbol, input_size=2000, output_size=100):\n    # Get Prediction Result\n    stock_df = merged_df[merged_df['symbol'] == symbol]\n    predict_df = stock_df.tail(windows).reset_index()\n    pred_input_df = pd.concat([predict_df, predict_df.tail(1)], ignore_index=True)\n    predictions = TimeSeriesDataSet.from_dataset(training, pred_input_df)\n    pred_dataloader = predictions.to_dataloader(train=False, batch_size=batch_size)\n    predictions_out = best_tft.predict(\n        pred_dataloader, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator=\"auto\")\n    )\n    predictions_q = best_tft.predict(pred_dataloader)\n    median_forecast = predictions_q[:, 0]\n\n    # Plotting\n    import numpy as np\n    pred_size = 100\n    plt.plot(predict_df['Date'][-pred_size-1:].to_list() + ['next_day'], median_forecast.cpu()[-pred_size-2:], label=\"Predicted\", color=\"blue\", linewidth=2, linestyle=\"dashed\")\n    #plt.plot(low_forecast.cpu(), label=\"Lower Bound (5%)\", color=\"red\", linestyle=\"dashed\")\n    #plt.plot(high_forecast.cpu(), label=\"Upper Bound (95%)\", color=\"green\", linestyle=\"dashed\")\n    plt.plot(predict_df['Date'][-pred_size-1:], predict_df['Close'][-pred_size-1:], label=\"Actual\", color=\"black\")\n    \n    # # Labels and title\n    plt.xlabel(\"Date\")\n    plt.xticks(fontsize=8) \n    plt.xticks(np.arange(0, len(predict_df['Date'][-pred_size-1:]), 30))\n    plt.ylabel(\"Predicted Value\")\n    plt.title(f\"{symbol} Forecast\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T17:29:12.269969Z","iopub.execute_input":"2025-03-28T17:29:12.270252Z","iopub.status.idle":"2025-03-28T17:29:12.277335Z","shell.execute_reply.started":"2025-03-28T17:29:12.270231Z","shell.execute_reply":"2025-03-28T17:29:12.276389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_prediction(\"TSLA\")\ndisplay_prediction(\"AAPL\")\ndisplay_prediction(\"MSFT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T17:29:13.696057Z","iopub.execute_input":"2025-03-28T17:29:13.696340Z","iopub.status.idle":"2025-03-28T17:29:31.285398Z","shell.execute_reply.started":"2025-03-28T17:29:13.696319Z","shell.execute_reply":"2025-03-28T17:29:31.284466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for idx in range(10):  # plot 10 examples\n#     best_tft.plot_prediction(\n#         predictions.x,\n#         predictions.output,\n#         idx=idx,\n#         show_future_observed=True,\n#     )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}